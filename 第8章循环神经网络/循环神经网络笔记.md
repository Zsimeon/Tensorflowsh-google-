#1 循环神经网络

##循环神经网络简介

1. 循环神经网络的来源就是为了刻画一个序列当前输出与之前信息的关系

2. 在网络结构上，循环神经网络会记忆之前的信息，并利用之前的信息影响后面结点的输出

3. 循环神经网络的一个非常重要的概念就是**时刻**

4. 循环神经网络会对每一个是个的输入结合当前模型的状态给出一个输出

5. 在每一时刻循环神经网络的模块A会读取t时刻的输入X_t，并输出一个值h_t。
同时A的状态会从当前步传递到下一步。

因此循环神经网络理论上可以被看作是同一神经网络结构被无限复制的结果。

6. 从循环神经网络的结构特征可以看出它最擅长解决的问题时与时间序列相关的

7. 循环神经网络要求每一个时刻都有输入，但不一定每一个时刻都有输出

8. 循环神经网络可以看作是同一神经网络结构在实际序列上被复制多次的结果，这个复制多次的结构被称之为循环体。

9. 如何设计循环体的网络结构是循环神经网络解决实际问题的关键。

10. 在得到循环神经网络的前向传播结果之后，可以和其他神经网络类似地定义损失函数。

11. 循环神经网络唯一的区别在于因为它每个时刻都有一个输出，所以循环神经网络的总损失为所有时刻上的损失函数的总和。



## 长短时记忆网络  (LSTM)结构


1. LSTM靠一些“门”结构让信息有选择性地影响循环神经网络中每个时刻的状态。
所谓门就是一个使用sigmoid神经网络和一个按位做乘法的操作，这两个操作合在一起就是一个“门”的结构。



#2 循环神经网络的变种

## 双向循环神经网络和深层循环神经网络

1. 双向循环神经网络(bidirectional RNN)
是由两个循环神经网络上下叠加在一起组成的，输出由这两个循环神经网络的状态共同决定。

2. 在每一个时刻t，输入会同时提供给这两个方向相反的循环神经网络，而输出则是由这两个单向循环神经网络共同决定的。

3. 深层循环神经网络（deepRNN） 
可以将每一个时刻上的循环体重复多次，Tensorflow中提供了MultiRNNCell类来实现深层循环神经网络的前向传播过程

## 循环神经网络的dropout

通过dropout可以使神经网络更健壮（robust）

类似卷积神经网络只在最后的全连接层使用dropout，循环神经网络一般只在不同层循环体结构之间使用dropout，而不在同一层的循环体结构之间使用。

即从t-1时刻传递到t时刻时，循环神经网络不会进行状态的dropout；而在同一个时刻中，不同层循环体之间会使用dropout。



#3循环神经网络样例应用

## 1 自然语言建模

1. 语言模型的目的是为了计算一个句子的出现概率

2. 语言模型效果好坏的常用评价指标是复杂度（perplexity），简单来说，perplecity值刻画的就是通过某一个语言模型估计的一句话出现的概率

3. 复杂度perplexity表示的概念其实是平均分支系数（average branch factor），即模型预测下一个词时的平均可选择数量

**PTB文本数据集介绍***  PTB(Penn Treebank Dataset)文本数据集是语言模型学习中目前最广泛使用的数据集

数据下载地址为：
http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz

