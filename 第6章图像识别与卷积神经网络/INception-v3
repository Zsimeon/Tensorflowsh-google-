#Inception-v3模型中的Inception结构是将不同的卷积层通过并联的方式结合在一起
#一个卷积层可以使用边长为1、3、5的过滤器，那么如何在这些边长中选呢
#Inception给了一个俺干，就是同时使用所有不同尺寸的过滤器，然后再将得到的矩阵拼接起来

#虽然过滤器的大小不同，但如果所有过滤器都使用全0填充且步长为1，那么前向传播的到
#的结果矩阵可以拼接策划给你一个更深的矩阵



############################
#以下代码对比了直接使用tensorflow实现一个卷积层和使用tf-Slim实现同样结果的神经网络的代码量

#直接使用TensorFlow原始API实现卷积层
with tf.variable_scope(scope_name):
	weights = tf.get_variable("weight",...)
	biases = tf.get_variable("bias",...)
	conv = tf.nn.conv2d(...)
relu = tf.nn.relu(tf.nn.bias_add(conv,biases))

# 使用Tensorflow-Slim实现卷积层。通过Tensorflow-Slim可以在一行中实现一个卷积层的前向传播算法
# slim.conv2d函数有3个参数是必填的。
# 第一个参数为输入节点矩阵，
# 第二个参数是当前卷积层过滤器的深度
# 第三个参数是过滤器的尺寸。
# 可选的参数有过滤器移动的步长、是否使用全0填充，
# 激活函数的选择以及变量的命名空间等
net = slim.conv2d(input, 32, [3,3])


###################################################
#以下为Inception-v3模型中结构相对复杂的一个Inception模块的代码

# slim.arg_scope函数可用于设置默认的参数取值，slim.arg_scope函数的第一个参数是
# 一个函数列表，在这个列表中的函数将使用默认的参数取值，调用slim.conv2d(net,320,[1,1])
# 函数时会自动加上stride=1和padding='SAME'的参数。如果在函数调用时指定了stride，
# 那么这里设置的默认值就不会再使用。通过这种方式可以进一步减少冗余代码
with slim.arg_scope([slim.conv2d,slim.max_pool2d,slim.avg_pool2d],
	stride = 1, padding = 'SAME')
	...
	# 此处省略了Inception-v3模型中其他的网络结构而直接实现最后面红色方框中的Inception结构
	# 假设输入图片经过之前的神经网络前向传播的结果保存在变量net中
	net = 上一层输出的节点结构
	#为一个Inception模块声明一个统一的变量命名空间
	with tf.variable_scope('Branch_1'):
		branch_1 = slim.conv2d(net,384,[1,1],scope='Conv2d_0a_1x1')
		#tf.concat函数可以将多个矩阵拼接起来，tf.concat函数的第一个参数指定了拼接的维度
		#这里给出“3”代表了矩阵是在深度这个维度上进行拼接
		branch_1 = tf.concat(3,[
			slim.conv2d(branch_1,384,[1,3],scope='Conv2d_0b_1x3'),
			slim.conv2d(branch_1,384,[3,1],scope='Conv2d_0c_3x1')])

	#Inception模块中的第三条路径，此计算路径也是一个Inception结构
	with tf.variable_scope('Branch_2'):
		branch_2 = slim.conv2d(
			net,448,[1,1],scope='Conv2d_0a_1x1')
		branch_2 = slim.conv2d(
			branch_2,384,[3,3],scope = 'Conv2d_0b_3x3')
		branch_2 = tf.concat(3,[
			slim.conv2d(branch_2,384,
				[1,3],scope='Conv2d_0c_1x3'),
			slim.conv2d(branch_2,384,
				[3,1],scope='Conv2d_0d_3x1')])

	#Inception模块中的第四条路径
	with tf.variable_scope('Branch_3'):
		branch_3 = slim.avg_pool2d(
			net,[3,3],scope='AvgPool_0a_3x3')
		branch_3 = slim.conv2d(
			branch_3,192,[1,1],scope='Conv2d_0b_1x1')

	#当前Inception模块最后输出是由上面四个计算结果拼接得到的
	net = tf.concat(3,[branch_0,branch_1,branch_2,branch_3])
	


